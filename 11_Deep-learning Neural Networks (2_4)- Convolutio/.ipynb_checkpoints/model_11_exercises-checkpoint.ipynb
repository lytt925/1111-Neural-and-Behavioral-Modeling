{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural & Behavioral Modeling - Week 11 (Exercises)\n",
    "by Your Name (Your Email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True \n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import *\n",
    "from IPython.display import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU status:\n",
    "import torch as t\n",
    "print('PyTorch version:',t.__version__)\n",
    "use_cuda=t.cuda.is_available()\n",
    "if(use_cuda):\n",
    "    for i in range(t.cuda.device_count()):\n",
    "        print('Device ',i,':',t.cuda.get_device_name(i))\n",
    "    print('Current: Device ',t.cuda.current_device())\n",
    "    t.backends.cudnn.benchmark = True \n",
    "    device = t.device(\"cuda\")\n",
    "else:\n",
    "    device = t.device(\"cpu\")\n",
    "    print('No GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Fair Performance Evaluation (2 points)\n",
    "We often compare and assess performances of different model architectures/parameters/hyperparameters. Note that the results are differnt even if you re-run exactly the same code block. This is primarily due to a non-fixed random number seed. Please:\n",
    "\n",
    "(1) run the section 1.2 TEN times and report (a) min, (b) max, (c) mean, & (d) standard deviation of the TESTING accuracies. (2 points)\n",
    "\n",
    "(2) try to fix the random number seeds in numpy & pytorch to see if you can obtain the same results every time in the section 1.2. (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset:\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "train_set = CIFAR10(root='.', train=True, transform=transforms.ToTensor())\n",
    "train_data = t.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_set = CIFAR10(root='.', train=False, transform=transforms.ToTensor())\n",
    "test_data = t.utils.data.DataLoader(train_set, batch_size=1000, shuffle=True)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model:\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() # = nn.Module.__init__(self)\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # in, out, kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) \n",
    "        self.fc1   = nn.Linear(16*5*5, 120) \n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "    def forward(self, x): # functional expressions\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) \n",
    "        x = x.view(x.size()[0], -1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)        \n",
    "        return x\n",
    "lenet = Net()\n",
    "lenet = lenet.to(device)\n",
    "loss_fn = t.nn.CrossEntropyLoss()\n",
    "optimizer = t.optim.Adam(lenet.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training:\n",
    "for e in range(2):\n",
    "    for i, (X_train, Y_train) in enumerate(train_data, 0):\n",
    "        X_train,Y_train=X_train.to(device),Y_train.to(device)\n",
    "        Y_pred = lenet(X_train)\n",
    "        loss = loss_fn(Y_pred, Y_train)\n",
    "        lenet.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()   \n",
    "        Y_pred = lenet(X_train)\n",
    "        Y_pred = t.max(Y_pred,1)[1]\n",
    "    print('epoch ',e,':',(Y_pred==Y_train).sum().item()/Y_train.shape[0])\n",
    "    \n",
    "# Testing on a batch:\n",
    "dataiter = iter(test_data)\n",
    "X_test, Y_test = dataiter.next() # returning a batch\n",
    "X_test,Y_test=X_test.to(device),Y_test.to(device)\n",
    "with t.no_grad():\n",
    "    Y_pred = lenet(X_test)\n",
    "    Y_pred = t.max(Y_pred,1)[1]\n",
    "    print('test :',(Y_pred==Y_test).sum().item()/Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Your answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please respond to the questions here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Universal Approximation Theorem (4 points)\n",
    "\n",
    "Please FAIRLY evaluate whether a deep network learns XOR more efficiently than a shallow network with the same number of model parameters. Please discuss why in either case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 XOR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5c07c72b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N=1000 # samples per cluster\n",
    "XY=t.tensor([[5,5],[5,10],[10,5],[10,10]],dtype=t.float32) # 4 cluster centers\n",
    "Z=t.tensor([0,1,1,0]) # category labels\n",
    "t.cat([t.randn(2,1)+XY[0,0],t.randn(2,1)+XY[0,1]],1)\n",
    "xy,z=t.zeros(4*N,2),t.zeros(4*N,dtype=t.int64)\n",
    "for i in range(4):\n",
    "    xy[i*N:(i+1)*N,]=t.rand(N,2)+XY[i,]\n",
    "    z[i*N:(i+1)*N]=Z[i]\n",
    "xy_np=xy.numpy()\n",
    "z_np=z.numpy().astype(int)\n",
    "cmap=np.array([[1,0,0],[0,1,0]])\n",
    "scatter(xy_np[:,0],xy_np[:,1],color=cmap[z_np]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 A shallow net with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of free parameters: 2*H+H*2=48\n",
    "\n",
    "H=12 # number of hidden units\n",
    "model = t.nn.Sequential(\n",
    "    t.nn.Linear(2, H, bias=False),\n",
    "    t.nn.BatchNorm1d(H),\n",
    "    t.nn.ReLU(),\n",
    "    t.nn.Linear(H, 2, bias=False),\n",
    "    t.nn.Softmax(dim=1)\n",
    ")\n",
    "loss_fn = t.nn.CrossEntropyLoss()\n",
    "optimizer = t.optim.Adam(model.parameters())\n",
    "\n",
    "for i in range(100):\n",
    "    z_pred = model(xy)\n",
    "    loss = loss_fn(z_pred,z)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    z_pred = model(xy) \n",
    "    z_pred = t.max(z_pred,1)[1]\n",
    "    print('epoch ',i,':',(z_pred==z).sum().item()/xy.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 A \"deep\" net with three hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of free parameters: 2*H+H*H+H*H+H*2=48\n",
    "\n",
    "H=4 # number of hidden units\n",
    "model = t.nn.Sequential(\n",
    "    t.nn.Linear(2, H, bias=False),\n",
    "    t.nn.BatchNorm1d(H),\n",
    "    t.nn.ReLU(),\n",
    "    t.nn.Linear(H, H,bias=False),\n",
    "    t.nn.BatchNorm1d(H),\n",
    "    t.nn.ReLU(),\n",
    "    t.nn.Linear(H, H, bias=False),\n",
    "    t.nn.BatchNorm1d(H),\n",
    "    t.nn.ReLU(),\n",
    "    t.nn.Linear(H, 2, bias=False),\n",
    "    t.nn.Softmax(dim=1)\n",
    ")\n",
    "loss_fn = t.nn.CrossEntropyLoss()\n",
    "optimizer = t.optim.Adam(model.parameters())\n",
    "\n",
    "for i in range(100):\n",
    "    z_pred = model(xy)\n",
    "    loss = loss_fn(z_pred,z)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    z_pred = model(xy) \n",
    "    z_pred = t.max(z_pred,1)[1]\n",
    "    print('epoch ',i,':',(z_pred==z).sum().item()/xy.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Your answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please respond to the questions here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
